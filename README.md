# Back-Propagation-Algorithm
Backpropagation is an algorithm used for training artificial neural networks. It adjusts the weights of the network during the backward pass to minimize the difference between predicted and actual output using the gradient descent optimization algorithm. It is effective for deep neural networks but may suffer from the vanishing gradient problem
